
<!DOCTYPE html>


<html lang="en" data-content_root="./" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="viewport" content="width=device-width, initial-scale=1" />

    <title>3. Training and Testing &#8212; Fair-Candidate-Screening-System 0.1 documentation</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "";
  </script>
  <!--
    this give us a css class that will be invisible only if js is disabled
  -->
  <noscript>
    <style>
      .pst-js-only { display: none !important; }

    </style>
  </noscript>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="_static/styles/theme.css?digest=8878045cc6db502f8baf" rel="stylesheet" />
<link href="_static/styles/pydata-sphinx-theme.css?digest=8878045cc6db502f8baf" rel="stylesheet" />

    <link rel="stylesheet" type="text/css" href="_static/pygments.css?v=8f2a1f02" />
  
  <!-- So that users can add custom icons -->
  <script src="_static/scripts/fontawesome.js?digest=8878045cc6db502f8baf"></script>
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="_static/scripts/bootstrap.js?digest=8878045cc6db502f8baf" />
<link rel="preload" as="script" href="_static/scripts/pydata-sphinx-theme.js?digest=8878045cc6db502f8baf" />

    <script src="_static/documentation_options.js?v=2709fde1"></script>
    <script src="_static/doctools.js?v=9bcbadda"></script>
    <script src="_static/sphinx_highlight.js?v=dc90522c"></script>
    <script crossorigin="anonymous" integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'training_testing';</script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  <meta name="docsearch:version" content="" />
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <div id="pst-skip-link" class="skip-link d-print-none"><a href="#main-content">Skip to main content</a></div>
  
  <div id="pst-scroll-pixel-helper"></div>
  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>Back to top</button>

  
  <dialog id="pst-search-dialog">
    
<form class="bd-search d-flex align-items-center"
      action="search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         placeholder="Search the docs ..."
         aria-label="Search the docs ..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form>
  </dialog>

  <div class="pst-async-banner-revealer d-none">
  <aside id="bd-header-version-warning" class="d-none d-print-none" aria-label="Version warning"></aside>
</div>

  
    <header class="bd-header navbar navbar-expand-lg bd-navbar d-print-none">
<div class="bd-header__inner bd-page-width">
  <button class="pst-navbar-icon sidebar-toggle primary-toggle" aria-label="Site navigation">
    <span class="fa-solid fa-bars"></span>
  </button>
  
  
  <div class="col-lg-3 navbar-header-items__start">
    
      <div class="navbar-item">

  
    
  

<a class="navbar-brand logo" href="index.html">
  
  
  
  
  
  
    <p class="title logo__title">Fair-Candidate-Screening-System 0.1 documentation</p>
  
</a></div>
    
  </div>
  
  <div class="col-lg-9 navbar-header-items">
    
    <div class="me-auto navbar-header-items__center">
      
        <div class="navbar-item">
<nav>
  <ul class="bd-navbar-elements navbar-nav">
    
<li class="nav-item ">
  <a class="nav-link nav-internal" href="main.html">
    Fair Candidate Screening System
  </a>
</li>

  </ul>
</nav></div>
      
    </div>
    
    
    <div class="navbar-header-items__end">
      
        <div class="navbar-item navbar-persistent--container">
          

<button class="btn search-button-field search-button__button pst-js-only" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
 <i class="fa-solid fa-magnifying-glass"></i>
 <span class="search-button__default-text">Search</span>
 <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd class="kbd-shortcut__modifier">K</kbd></span>
</button>
        </div>
      
      
        <div class="navbar-item">

<button class="btn btn-sm nav-link pst-navbar-icon theme-switch-button pst-js-only" aria-label="Color mode" data-bs-title="Color mode"  data-bs-placement="bottom" data-bs-toggle="tooltip">
  <i class="theme-switch fa-solid fa-sun                fa-lg" data-mode="light" title="Light"></i>
  <i class="theme-switch fa-solid fa-moon               fa-lg" data-mode="dark"  title="Dark"></i>
  <i class="theme-switch fa-solid fa-circle-half-stroke fa-lg" data-mode="auto"  title="System Settings"></i>
</button></div>
      
    </div>
    
  </div>
  
  
    <div class="navbar-persistent--mobile">

<button class="btn search-button-field search-button__button pst-js-only" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
 <i class="fa-solid fa-magnifying-glass"></i>
 <span class="search-button__default-text">Search</span>
 <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd class="kbd-shortcut__modifier">K</kbd></span>
</button>
    </div>
  

  
    <button class="pst-navbar-icon sidebar-toggle secondary-toggle" aria-label="On this page">
      <span class="fa-solid fa-outdent"></span>
    </button>
  
</div>

    </header>
  

  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      
      
        
      
      <dialog id="pst-primary-sidebar-modal"></dialog>
      <div id="pst-primary-sidebar" class="bd-sidebar-primary bd-sidebar hide-on-wide">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
      <div class="sidebar-header-items__center">
        
          
          
            <div class="navbar-item">
<nav>
  <ul class="bd-navbar-elements navbar-nav">
    
<li class="nav-item ">
  <a class="nav-link nav-internal" href="main.html">
    Fair Candidate Screening System
  </a>
</li>

  </ul>
</nav></div>
          
        
      </div>
    
    
    
      <div class="sidebar-header-items__end">
        
          <div class="navbar-item">

<button class="btn btn-sm nav-link pst-navbar-icon theme-switch-button pst-js-only" aria-label="Color mode" data-bs-title="Color mode"  data-bs-placement="bottom" data-bs-toggle="tooltip">
  <i class="theme-switch fa-solid fa-sun                fa-lg" data-mode="light" title="Light"></i>
  <i class="theme-switch fa-solid fa-moon               fa-lg" data-mode="dark"  title="Dark"></i>
  <i class="theme-switch fa-solid fa-circle-half-stroke fa-lg" data-mode="auto"  title="System Settings"></i>
</button></div>
        
      </div>
    
  </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
      <div class="sidebar-primary-item">
<div id="ethical-ad-placement"
      class="flat"
      data-ea-publisher="readthedocs"
      data-ea-type="readthedocs-sidebar"
      data-ea-manual="true">
</div></div>
  </div>


      </div>
      
      <main id="main-content" class="bd-main" role="main">
        
        
          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article d-print-none">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item">

<nav aria-label="Breadcrumb" class="d-print-none">
  <ul class="bd-breadcrumbs">
    
    <li class="breadcrumb-item breadcrumb-home">
      <a href="index.html" class="nav-link" aria-label="Home">
        <i class="fa-solid fa-home"></i>
      </a>
    </li>
    <li class="breadcrumb-item active" aria-current="page"><span class="ellipsis">3. Training and Testing</span></li>
  </ul>
</nav>
</div>
      
    </div>
  
  
</div>
</div>
              
              
              
                
<div id="searchbox"></div>
                <article class="bd-article">
                  
  <section id="training-and-testing">
<h1>3. Training and Testing<a class="headerlink" href="#training-and-testing" title="Link to this heading">#</a></h1>
<p>This section describes the training and evaluation process for the classification models, including both standard (no mitigation) and fairness-aware (with mitigation) approaches. All models are validated using a 5-fold cross-validation strategy.</p>
<section id="evaluation-setup">
<h2>Evaluation Setup<a class="headerlink" href="#evaluation-setup" title="Link to this heading">#</a></h2>
<ul class="simple">
<li><p><strong>Validation strategy:</strong> 5-fold cross-validation</p></li>
<li><p><strong>Metrics:</strong>
- <strong>Performance metrics:</strong> Accuracy, Precision, Recall, F1-score, AUC
- <strong>Fairness metrics:</strong> Demographic Parity, Equalized Odds Ratio</p></li>
<li><p><strong>Comparison:</strong> Results are shown both <strong>with</strong> and <strong>without mitigation techniques</strong></p></li>
</ul>
</section>
<section id="visualization">
<h2>Visualization<a class="headerlink" href="#visualization" title="Link to this heading">#</a></h2>
<p>The following plots are generated to visualize performance and fairness:</p>
<ul class="simple">
<li><p><strong>Performance column bar plot:</strong>
Displays mean ± standard deviation across folds for each performance metric
(two subplots: <em>without</em> mitigation, <em>with</em> mitigation)</p></li>
<li><p><strong>Fairness column bar plot:</strong>
Displays mean ± standard deviation across folds for each fairness metric
(two subplots: <em>without</em> mitigation, <em>with</em> mitigation)</p></li>
</ul>
</section>
<section id="pre-processing-mitigation">
<h2>3.1 Pre-processing Mitigation<a class="headerlink" href="#pre-processing-mitigation" title="Link to this heading">#</a></h2>
<p>Pre-processing mitigation techniques are applied <strong>before training</strong> to reduce bias in the data itself.</p>
<ul class="simple">
<li><p>A comparison is made between the <strong>original dataset</strong> and the <strong>transformed dataset</strong> using a coordinate plot</p></li>
<li><p>Techniques used may include:
- Reweighting
- Resampling (e.g., oversampling minority group)
- Fair representation learning (e.g., learning latent fair embeddings)</p></li>
</ul>
<p>These methods aim to remove correlations between sensitive features and the target variable before any model sees the data.</p>
</section>
<section id="in-processing-mitigation">
<h2>3.2 In-processing Mitigation<a class="headerlink" href="#in-processing-mitigation" title="Link to this heading">#</a></h2>
<p>In-processing methods are applied <strong>during model training</strong>, modifying the learning process itself to enforce fairness constraints directly within the optimization loop.</p>
<p>We experimented with three main fairness-aware algorithms:</p>
<ul class="simple">
<li><p><strong>Adversarial Debiasing</strong></p></li>
<li><p><strong>FaUCI (Fair Uncertainty-aware Classification Index)</strong></p></li>
<li><p><strong>Prejudice Removal</strong></p></li>
</ul>
<p>These methods aim to <strong>jointly optimize predictive performance and fairness</strong>, using different fairness regularization strategies.</p>
<p>Among these, <strong>Adversarial Debiasing consistently achieved the best trade-off</strong> between fairness and accuracy. It works by introducing an adversarial component that learns to predict the sensitive attribute, while the main model is trained to minimize its predictive power. This leads to internal representations that are less biased and more equitable across groups.</p>
<p>In contrast, <strong>FaUCI and Prejudice Removal</strong> showed limited improvement in fairness, even when tuning regularization strengths (<cite>lambda</cite>, <cite>eta</cite>). The main bottleneck was the <strong>lack of sufficient examples from minority sensitive groups</strong>, which prevented the algorithms from learning generalizable fairness constraints. Data augmentation partially mitigated this issue, improving fairness outcomes for underrepresented subgroups.</p>
<p>Furthermore, we observed that <strong>fairness metrics degraded when using standard k-fold cross-validation</strong>, due to the absence of stratification over sensitive attributes. Some folds lacked representation for certain groups, making fairness evaluation unreliable. When using a <strong>stratified split based on the sensitive feature</strong>, both fairness training and evaluation improved significantly.</p>
<p>For this reason, we strongly recommend using <strong>stratified cross-validation over sensitive attributes</strong> when training and evaluating fairness-aware models.</p>
</section>
<section id="analysis-of-in-processing-techniques">
<h2>3.3 Analysis of In-processing Techniques<a class="headerlink" href="#analysis-of-in-processing-techniques" title="Link to this heading">#</a></h2>
<p>This section focuses on the evaluation of in-processing mitigation strategies used during model training. The primary goal was to reduce bias while maintaining model performance.</p>
</section>
<section id="adversarial-debiasing">
<h2>Adversarial Debiasing<a class="headerlink" href="#adversarial-debiasing" title="Link to this heading">#</a></h2>
<p>Among the methods tested, <strong>Adversarial Debiasing</strong> showed the most promising results across both fairness and performance metrics.</p>
<ul class="simple">
<li><p>This technique trains a secondary adversarial model that tries to <strong>predict the sensitive attribute</strong> from the main model’s internal representation.</p></li>
<li><p>Simultaneously, the main model is optimized to <strong>prevent the adversary from succeeding</strong>, thereby learning representations that are <strong>informative but not biased</strong>.</p></li>
<li><p>In our experiments, Adversarial Debiasing consistently <strong>reduced Disparity Metrics</strong> such as Demographic Parity and Equalized Odds, while maintaining high performance (e.g., F1-score, AUC).</p></li>
<li><p>It also proved to be <strong>robust with minimal hyperparameter tuning</strong>, making it the most effective of the evaluated in-processing techniques.</p></li>
</ul>
</section>
<section id="fauci-and-prejudice-removal">
<h2>FaUCI and Prejudice Removal<a class="headerlink" href="#fauci-and-prejudice-removal" title="Link to this heading">#</a></h2>
<p>The other two in-processing methods—<strong>FaUCI</strong> and <strong>Prejudice Removal</strong>—showed limited effectiveness, even when increasing regularization parameters such as <cite>lambda</cite> and <cite>eta</cite>.</p>
<ul class="simple">
<li><p>These methods <strong>did not significantly improve fairness metrics</strong> in our initial tests.</p></li>
<li><p>A key issue was the <strong>lack of representative samples</strong> for combinations of sensitive groups and target classes.</p></li>
<li><p>Without enough examples in underrepresented subgroups, these methods struggled to learn fair decision boundaries.</p></li>
<li><p>We addressed this limitation by applying <strong>targeted data augmentation</strong>, which improved fairness results and highlighted the importance of <strong>balanced subgroup representation</strong>.</p></li>
</ul>
</section>
<section id="effect-of-cross-validation">
<h2>Effect of Cross-Validation<a class="headerlink" href="#effect-of-cross-validation" title="Link to this heading">#</a></h2>
<p>An unexpected observation was that fairness metrics were generally <strong>better when using a simple train/test split</strong> compared to k-fold cross-validation.</p>
<ul class="simple">
<li><p>This is due to the fact that <strong>standard cross-validation does not guarantee balanced representation of sensitive subgroups</strong> across folds.</p></li>
<li><p>Some folds may contain very few or no examples from certain sensitive groups, causing instability in fairness metrics and poor generalization.</p></li>
</ul>
<p>To overcome this, we recommend using <strong>stratified cross-validation based on the sensitive attribute</strong>. This ensures each fold contains a proportional representation of all sensitive subgroups and allows for more <strong>reliable fairness evaluation</strong>.</p>
</section>
<section id="key-takeaways">
<h2>Key Takeaways<a class="headerlink" href="#key-takeaways" title="Link to this heading">#</a></h2>
<ul class="simple">
<li><p><strong>Adversarial Debiasing</strong> is the most effective in-processing mitigation strategy in this study.</p></li>
<li><p><strong>Fairness performance is highly sensitive to subgroup representation</strong> in the dataset.</p></li>
<li><p><strong>Data augmentation</strong> can help improve fairness when subgroup data is sparse.</p></li>
<li><p>Always use <strong>stratified cross-validation over sensitive features</strong> for fairness-aware model evaluation.</p></li>
</ul>
</section>
</section>


                </article>
              
              
              
              
              
                <footer class="prev-next-footer d-print-none">
                  
<div class="prev-next-area">
</div>
                </footer>
              
            </div>
            
            
              
                <dialog id="pst-secondary-sidebar-modal"></dialog>
                <div id="pst-secondary-sidebar" class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">


  <div class="sidebar-secondary-item">
<div
    id="pst-page-navigation-heading-2"
    class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> On this page
  </div>
  <nav class="bd-toc-nav page-toc" aria-labelledby="pst-page-navigation-heading-2">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#evaluation-setup">Evaluation Setup</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#visualization">Visualization</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#pre-processing-mitigation">3.1 Pre-processing Mitigation</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#in-processing-mitigation">3.2 In-processing Mitigation</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#analysis-of-in-processing-techniques">3.3 Analysis of In-processing Techniques</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#adversarial-debiasing">Adversarial Debiasing</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#fauci-and-prejudice-removal">FaUCI and Prejudice Removal</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#effect-of-cross-validation">Effect of Cross-Validation</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#key-takeaways">Key Takeaways</a></li>
</ul>
  </nav></div>

  <div class="sidebar-secondary-item">
  <div role="note" aria-label="source link">
    <h3>This Page</h3>
    <ul class="this-page-menu">
      <li><a href="_sources/training_testing.rst.txt"
            rel="nofollow">Show Source</a></li>
    </ul>
   </div></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
          </footer>
        
      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script defer src="_static/scripts/bootstrap.js?digest=8878045cc6db502f8baf"></script>
<script defer src="_static/scripts/pydata-sphinx-theme.js?digest=8878045cc6db502f8baf"></script>

  <footer class="bd-footer">
<div class="bd-footer__inner bd-page-width">
  
    <div class="footer-items__start">
      
        <div class="footer-item">

  <p class="sphinx-version">
    Created using <a href="https://www.sphinx-doc.org/">Sphinx</a> 8.1.3.
    <br/>
  </p>
</div>
      
    </div>
  
  
  
    <div class="footer-items__end">
      
        <div class="footer-item">
<p class="theme-version">
  <!-- # L10n: Setting the PST URL as an argument as this does not need to be localized -->
  Built with the <a href="https://pydata-sphinx-theme.readthedocs.io/en/stable/index.html">PyData Sphinx Theme</a> 0.16.1.
</p></div>
      
    </div>
  
</div>

  </footer>
  </body>
</html>